{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Cosine Similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tltr: Script for computing semantic similarity between 2 words (a target word and what the participants memory or guess of it is) using a pretrained GloVe word embedding glove.6B.100d "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What problem does this notebook help you solve?\n",
    "\n",
    "In psychological research, participants are often asked to recall a previously seen word or guess a word based on some features (e.g., watching a muted video in which the word is discussed). If their response is the same as the correct answer, they receive a correct score. However, if the response is incorrect, in some case we want to know how incorrect it is. This can help us score the responses better. For example, if the answer is \"apple,\" we would give this trial a higher score than if the response is \"kettle\" since \"pear\" is more similar to \"apple\" than \"kettle.\" To achieve this, we can use a semantic similarity measure such as cosine distance between the vectors that represent the given words in a word embedding. In this tutorial, we use a pretrained GloVe embedding. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the pretrained [GloVe](https://nlp.stanford.edu/projects/glove/) word embedding glove.6B.100d - which should be downloaded from the https://nlp.stanford.edu/projects/glove/ and saved in trained_glove folder. This word embedding has 8 billion tokens and 100 dimentions. You can also use different pretrained GloVe word embeddings e.g., the glove.6B.300d with 300 dimension. \n",
    "\n",
    "\n",
    "Before looking at the cosine distance, participaints' responses are autocorrected using [symspellpy](https://symspellpy.readthedocs.io/en/latest/examples/lookup.html#basic-usage) and both participants responses and the answers are lemmatized using [Stanza](https://stanfordnlp.github.io/stanza/lemma.html).\n",
    "\n",
    "\n",
    "Required packages: \n",
    "- pandas \n",
    "- gensim\n",
    "- symspellpy \n",
    "- stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up for cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an absolute path to training set from relative path\n",
    "root_folder='.'\n",
    "data_folder_name='trained_glove'\n",
    "glove_filename='glove.6B.100d.txt' # edit as required\n",
    "DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n",
    "glove_path = os.path.abspath(os.path.join(DATA_PATH, glove_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-358018b0fe0a>:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_path, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the `glove_input_file` in GloVe format to word2vec format and write it to `word2vec_output_file`\n",
    "word2vec_output_file = glove_filename+'.word2vec'\n",
    "glove2word2vec(glove_path, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KeyedVectors from the word2vec_output_file produced by the original C word2vec-tool format.\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between potato & garlic = 0.4077409505844116\n",
      "distance between onion & garlic = 0.13924723863601685\n"
     ]
    }
   ],
   "source": [
    "# test if working \n",
    "print(\"distance between potato & garlic = \" + str(model.distance('potato','garlic')))\n",
    "print(\"distance between onion & garlic = \" + str(model.distance('onion','garlic')))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onion is closer to garlic than it is to potato, which makes sense. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up for autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up how SymSpell functions \n",
    "# max_dictionary_edit_distance: Maximum edit distance for doing lookups.\n",
    "# prefix_length: The length of word prefixes used for spell checking.\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "\n",
    "# load dictionary to spell checker. \n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
    ")\n",
    "# term_index is the column of the term and count_index is the\n",
    "# column of the term frequency\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "memebers\n",
      "suggestions: \n",
      "members, 1, 226656153\n",
      "input: \n",
      "chatalainee\n",
      "suggestions: \n",
      "chatelaine, 2, 86807\n",
      "input: \n",
      "papple\n",
      "suggestions: \n",
      "apple, 1, 50551171\n",
      "dapple, 1, 62176\n",
      "popple, 1, 34253\n"
     ]
    }
   ],
   "source": [
    "# see if it works! \n",
    "input_terms = [\n",
    "    \"memebers\",  # misspelling of \"members\"\n",
    "    \"chatalainee\", # misspelling of \"chatelaine\"\n",
    "    \"papple\"\n",
    "]\n",
    "for input_term in input_terms:\n",
    "    print(\"input: \")\n",
    "    print(input_term)\n",
    "    suggestions = sym_spell.lookup(input_term, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "    print(\"suggestions: \")\n",
    "    for suggestion in suggestions:\n",
    "        print(suggestion)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\n\\.conda\\envs\\dsenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: 193kB [00:00, 55.3MB/s]                    \n",
      "2022-12-12 11:07:23 INFO: Downloading default packages for language: en (English) ...\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/default.zip: 100%|██████████| 561M/561M [00:15<00:00, 36.7MB/s] \n",
      "2022-12-12 11:07:48 INFO: Finished downloading models and saved to C:\\Users\\n\\stanza_resources.\n",
      "2022-12-12 11:07:48 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: 193kB [00:00, 48.3MB/s]                    \n",
      "2022-12-12 11:07:50 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-12-12 11:07:50 INFO: Use device: cpu\n",
      "2022-12-12 11:07:50 INFO: Loading: tokenize\n",
      "2022-12-12 11:07:50 INFO: Loading: pos\n",
      "2022-12-12 11:07:51 INFO: Loading: lemma\n",
      "2022-12-12 11:07:51 INFO: Loading: depparse\n",
      "2022-12-12 11:07:51 INFO: Loading: sentiment\n",
      "2022-12-12 11:07:52 INFO: Loading: constituency\n",
      "2022-12-12 11:07:53 INFO: Loading: ner\n",
      "2022-12-12 11:07:54 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# set up Stanza for lemma \n",
    "import stanza\n",
    "stanza.download('en') # only need to run this the first time \n",
    "stanza_nlp = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:16:32 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: 193kB [00:00, 64.4MB/s]                    \n",
      "2022-12-12 11:16:32 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-12-12 11:16:32 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "========================\n",
      "\n",
      "2022-12-12 11:16:32 INFO: Use device: cpu\n",
      "2022-12-12 11:16:32 INFO: Loading: tokenize\n",
      "2022-12-12 11:16:32 INFO: Loading: pos\n",
      "2022-12-12 11:16:33 INFO: Loading: lemma\n",
      "2022-12-12 11:16:33 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the lemma of [ran] is [run]\n"
     ]
    }
   ],
   "source": [
    "# see if it works!\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
    "\n",
    "word2lemma = 'ran' \n",
    "doc = nlp(word2lemma)\n",
    "lemmad_word = doc.sentences[0].words[0].lemma\n",
    "print('the lemma of ['+word2lemma+'] is ['+lemmad_word+']')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up utility dictionaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the study this code was used we wanted to give a full score to certain words that were either typos or a synonyme. answekey contains these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the answer is good enough\n"
     ]
    }
   ],
   "source": [
    "answerkey = {\n",
    "  'toucan': 'tucan',\n",
    "  'castanets': 'castagnette',\n",
    "  'binoculars': 'lorgnette',\n",
    "  'scissors': ['scizor','scisor'],\n",
    "  'leek': 'leak',\n",
    "  'kazoo': ['cazoo', 'kazu'],\n",
    "  'pan' : 'frying pan',\n",
    "  'anteater' : 'ant eater',\n",
    "  'pliers' : ['pliers','plier']\n",
    "}\n",
    "\n",
    "answer = 'kazoo'\n",
    "response = 'kazu'\n",
    "if answer in answerkey.keys():\n",
    "    good_enough_answer = answerkey[answer]\n",
    "    if response in good_enough_answer:\n",
    "    # set cos dist to 0 \n",
    "        print('the answer is good enough')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also used a list of words that a lot of participants to say they didn't remember. This was prefered over allowing the code to just generate a large distance value for speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_answers = ['?','??','=','can,t guess', \"can't answer\",\"can't guess\",\"cannot guess\",\n",
    "\"canot guess\",\"cant guess\",\"cant tell\", \"cant' guess\", \"don't know\",\"don't know again\",\n",
    "\"don't know again\",\"don't know at all I'm afraid\", \"don't know here, having trouble with the English accents in these videos\",\n",
    "\"dont know\",\"no beep\",\"no clue\",\"no guess\",\"no idea\",\"no idea on that one\",\"no selection\",\n",
    "\"no word\",\"not sure\",\"not sure here at all\",\"nan\"]\n",
    "\n",
    "for i in range(len(no_answers)):\n",
    "    no_answers[i] = no_answers[i].lower()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse the responses  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there were 3 errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANSWER</th>\n",
       "      <th>Response</th>\n",
       "      <th>autocorrected</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>cosine_dist</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xylophone</td>\n",
       "      <td>xylophone</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peacock</td>\n",
       "      <td>horses</td>\n",
       "      <td>horses</td>\n",
       "      <td>horse</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spade</td>\n",
       "      <td>showel</td>\n",
       "      <td>showed</td>\n",
       "      <td>show</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pot</td>\n",
       "      <td>bowl</td>\n",
       "      <td>bowl</td>\n",
       "      <td>bowl</td>\n",
       "      <td>0.5847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sausage</td>\n",
       "      <td>burger</td>\n",
       "      <td>burger</td>\n",
       "      <td>burger</td>\n",
       "      <td>0.5398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple</td>\n",
       "      <td>pear</td>\n",
       "      <td>pear</td>\n",
       "      <td>pear</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>banana</td>\n",
       "      <td>banana</td>\n",
       "      <td>banana</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sausage</td>\n",
       "      <td>sausages</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>parrot</td>\n",
       "      <td>bird</td>\n",
       "      <td>bird</td>\n",
       "      <td>bird</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kettle</td>\n",
       "      <td>shoe</td>\n",
       "      <td>shoe</td>\n",
       "      <td>shoe</td>\n",
       "      <td>0.9019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pumkip</td>\n",
       "      <td>window</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>papaya</td>\n",
       "      <td>papaya</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hedgehog</td>\n",
       "      <td>fur</td>\n",
       "      <td>fur</td>\n",
       "      <td>fur</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mouse</td>\n",
       "      <td>rat</td>\n",
       "      <td>rat</td>\n",
       "      <td>rat</td>\n",
       "      <td>0.3556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>egg</td>\n",
       "      <td>no idea</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>horse</td>\n",
       "      <td>horse</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hammer</td>\n",
       "      <td>hammer</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>avocado</td>\n",
       "      <td>avocado</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>parsley</td>\n",
       "      <td>pesto</td>\n",
       "      <td>pesto</td>\n",
       "      <td>pesto</td>\n",
       "      <td>0.4362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ANSWER   Response autocorrected lemmatized cosine_dist  correct\n",
       "0   xylophone  xylophone            []         []          []        1\n",
       "1     peacock     horses        horses      horse       0.678        0\n",
       "2       spade     showel        showed       show      0.7993        0\n",
       "3         pot       bowl          bowl       bowl      0.5847        0\n",
       "4     sausage     burger        burger     burger      0.5398        0\n",
       "5      apple        pear          pear       pear       0.411        0\n",
       "6    mushroom     banana        banana     banana      0.6099        0\n",
       "7     sausage   sausages            []         []          []        1\n",
       "8      parrot       bird          bird       bird      0.4826        0\n",
       "9         cat        dog           dog        dog      0.1202        0\n",
       "10     kettle       shoe          shoe       shoe      0.9019        0\n",
       "11     pumkip     window            []         []          []        0\n",
       "12     papaya     papaya            []         []          []        1\n",
       "13   hedgehog        fur           fur        fur      0.9471        0\n",
       "14      mouse        rat           rat        rat      0.3556        0\n",
       "15        egg    no idea            []         []          []        0\n",
       "16      horse      horse            []         []          []        1\n",
       "17     hammer     hammer            []         []          []        1\n",
       "18    avocado    avocado            []         []          []        1\n",
       "19    parsley      pesto         pesto      pesto      0.4362        0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\",index_col=False)\n",
    "\n",
    "answer_response = data[['ANSWER', 'Response']].values.tolist()  # turn df to list\n",
    "# answer - what the currect answer to the task is\n",
    "# response - what the participant remembered and typed in\n",
    "\n",
    "outputs = [] # to store autocorrect, lemmatized, cos_dist, & correct\n",
    "error_n = 0\n",
    "\n",
    "for answer, response in answer_response:\n",
    "\n",
    "    # what participant has written (in lower case)\n",
    "    response = str(response).lower()\n",
    "\n",
    "    # Answers we manually decide are good enough\n",
    "    if (answer in answerkey.keys()):\n",
    "        good_enough_answer = answerkey[answer]\n",
    "        if response in good_enough_answer:\n",
    "            outputs.append([[],[],[],1]) # no autocorrect, no lemma, no cos dim, correct = 1 \n",
    "            continue\n",
    "\n",
    "    # responses that we are a \"I dont know/remember\" e.g. \"can't guess\"\n",
    "    if response in no_answers:\n",
    "        outputs.append([[],[],[],0]) # no autocorrect, no lemma, no cos dim, correct = 0\n",
    "        continue\n",
    "\n",
    "    # lemma the answer\n",
    "    answer_lemma = nlp(answer).sentences[0].words[0].lemma\n",
    "    word_correct = 0\n",
    "    if (answer_lemma in response) | (response in answer):\n",
    "        outputs.append([[],[],[],1]) # no autocorrect, no lemma, no cos dim, correct = 1 \n",
    "        continue\n",
    "\n",
    "    # for some words autocorrect will fail (because it can't correct it) and/or they dont exist in the vector space, these are skipped.\n",
    "    try:\n",
    "        # autocorrect\n",
    "        response_corrected = sym_spell.lookup(\n",
    "            response, Verbosity.CLOSEST, max_edit_distance=2)[0].term\n",
    "\n",
    "        # lemmatizer\n",
    "        response_lematize = nlp(response_corrected).sentences[0].words[0].lemma\n",
    "\n",
    "        # check if the response is the same as what it should be - this entail a correct response\n",
    "        word_correct = 0\n",
    "        if (response_lematize in answer_lemma):\n",
    "            word_correct = 1\n",
    "\n",
    "        # cosine distance rounded up to 4 decimal places \n",
    "        word_cosine = model.distance(answer_lemma, response_lematize).round(4)\n",
    "\n",
    "        outputs.append([response_corrected,response_lematize,word_cosine,word_correct]) # autocorrect, lemma, cos dim, correct = 0\n",
    "\n",
    "    except:  # if cos_dist is not found\n",
    "        #data2.cos_dist[w] = np.nan\n",
    "        error_n += 1\n",
    "        outputs.append([[],[],[],word_correct]) # no autocorrect, no lemma, no cos dim, correct = 1 \n",
    "        continue\n",
    "\n",
    "\n",
    "print(f\"there were {error_n} errors\")\n",
    "\n",
    "outputs_df = pd.DataFrame(outputs,columns=['autocorrected', 'lemmatized','cosine_dist','correct'])\n",
    "\n",
    "df = data.join(outputs_df)\n",
    "df.head(20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen in the above output, cosine distance is larger for semantically similar words (e.g., cat & dog) than for words that are less semantically similar (e.g., kettle & shoe)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de5855b65c1be67c11c2620c65f4cf26cfc1e3ad53e4a0c47f6a3e394181d372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
